<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>ChatIQ - AI Chat with Sessions</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Inter', sans-serif; scroll-behavior: smooth; }
        .chat-bubble-user { background-color: #DBEAFE; color: #1E3A8A; border-radius: 0.75rem; padding: 0.75rem 1rem; max-width: 80%; box-shadow: 0 1px 2px rgba(0,0,0,0.05); word-wrap: break-word; }
        .chat-bubble-bot { background-color: #D1FAE5; color: #065F46; border-radius: 0.75rem; padding: 0.75rem 1rem; max-width: 80%; box-shadow: 0 1px 2px rgba(0,0,0,0.05); word-wrap: break-word; }
        .image-chat-bubble { padding: 0.375rem; border-radius: 0.5rem; box-shadow: 0 1px 2px rgba(0,0,0,0.05); max-width: 60%; display: inline-block; }
        .image-chat-bubble img { max-width: 100%; height: auto; border-radius: 0.25rem; object-fit: contain; max-height: 20rem; }
        
        .chat-bubble-bot pre, .chat-bubble-user pre { background-color: #1F2937; color: #F3F4F6; padding: 1rem; border-radius: 0.5rem; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word; margin-top: 0.5rem; margin-bottom: 0.5rem;}
        .chat-bubble-bot code, .chat-bubble-user code { font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace; font-size: 0.875em; }

        #chatBox::-webkit-scrollbar, #sessionsList::-webkit-scrollbar { width: 6px; }
        #chatBox::-webkit-scrollbar-track, #sessionsList::-webkit-scrollbar-track { background: #F3F4F6; border-radius: 10px; }
        #chatBox::-webkit-scrollbar-thumb, #sessionsList::-webkit-scrollbar-thumb { background: #D1D5DB; border-radius: 10px; }
        #chatBox::-webkit-scrollbar-thumb:hover, #sessionsList::-webkit-scrollbar-thumb:hover { background: #9CA3AF; }
        
        .chat-input-bar-container { background-color: #F9FAFB; border-top: 1px solid #E5E7EB; }
        .control-button { padding: 0.625rem; /* 10px */ border-radius: 0.5rem; /* 8px */ display: flex; align-items: center; justify-content: center; transition: background-color 0.2s ease-in-out; }
        .control-button.glassmorphism { background-color: rgba(255, 255, 255, 0.2); backdrop-filter: blur(4px); }
        .control-button.glassmorphism:hover { background-color: rgba(255, 255, 255, 0.3); }
        .control-button svg { width: 1.25rem; height: 1.25rem; color: white; }
        @media (min-width: 640px) { .control-button svg { width: 1.5rem; height: 1.5rem; } }
        
        @keyframes textGradientShiftSubtle { 0% { background-position: 0% 50%; } 50% { background-position: 100% 50%; } 100% { background-position: 0% 50%; } }
        .animate-text-gradient-subtle { background-size: 250% 250%; animation: textGradientShiftSubtle 8s ease infinite; }
        #voiceInputBtn.recording .mic-icon-path { fill: #ef4444 !important; }

        .session-item { transition: background-color 0.2s ease-in-out; }
        .session-item.active { background-color: #DBEAFE; /* blue-100 */ color: #1E40AF; /* blue-800 */ font-weight: 600;}
        .session-item:hover:not(.active) { background-color: #EFF6FF; /* blue-50 */}
    </style>
</head>
<body class="bg-gray-100 text-gray-800 flex flex-col h-screen">

    <header class="relative bg-gradient-to-r from-cyan-500 to-indigo-600 text-white py-3 sm:py-4 shadow-lg overflow-hidden z-20">
        <div class="container mx-auto px-4 flex justify-between items-center">
            <div class="text-left">
                <h1 class="text-xl font-black tracking-tight sm:text-2xl lg:text-3xl 
                            text-transparent bg-clip-text bg-gradient-to-br from-pink-400 via-purple-400 to-red-500
                            animate-text-gradient-subtle">ChatIQ</h1>
            </div>
            <div id="authContainer" class="text-right flex items-center space-x-2">
                <button id="newChatBtn" class="hidden bg-green-500 hover:bg-green-600 text-white text-xs sm:text-sm font-semibold py-2 px-3 rounded-lg shadow-md transition duration-150 ease-in-out">New Chat</button>
                <button id="googleSignInBtnHeader" class="bg-white text-indigo-600 hover:bg-indigo-50 text-xs sm:text-sm font-semibold py-2 px-3 sm:px-4 rounded-lg shadow-md transition duration-150 ease-in-out">Sign in with Google</button>
                <div id="userDetailsHeader" class="hidden items-center">
                    <span id="userDisplayNameHeader" class="text-xs sm:text-sm mr-2 sm:mr-3 truncate max-w-[100px] sm:max-w-[150px]"></span>
                    <button id="signOutBtnHeader" class="bg-pink-500 hover:bg-pink-600 text-white text-xs sm:text-sm font-semibold py-2 px-3 rounded-lg shadow-md transition duration-150 ease-in-out">Sign Out</button>
                </div>
            </div>
        </div>
    </header>

    <div class="flex flex-1 overflow-hidden">
        <aside id="chatHistorySidebar" class="w-0 sm:w-64 bg-slate-50 border-r border-slate-200 flex-col p-3 space-y-2 overflow-y-auto transition-all duration-300 ease-in-out hidden">
            <h3 class="text-sm font-semibold text-slate-500 uppercase tracking-wider px-2">Chat History</h3>
            <div id="sessionsList" class="space-y-1">
                </div>
        </aside>

        <main class="flex-1 flex flex-col overflow-y-auto container mx-auto px-0 sm:px-2 py-4">
            <h4 class="text-center text-sm sm:text-base font-semibold
                text-transparent bg-clip-text 
                bg-gradient-to-r from-purple-500 via-pink-500 to-orange-500 
                drop-shadow-md 
                animate-text-gradient-subtle 
                inline-flex items-center justify-center space-x-1 w-full mb-4" id="swipeDownPrompt" style="display: none;">
                <span>Scroll to Discover More</span>
                 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-4 h-4 sm:w-5 sm:h-5 ml-1 opacity-90">
                   <path fill-rule="evenodd" d="M10 3a.75.75 0 01.75.75v10.69l2.47-2.47a.75.75 0 111.06 1.06l-3.75 3.75a.75.75 0 01-1.06 0L6.22 13.03a.75.75 0 011.06-1.06l2.47 2.47V3.75A.75.75 0 0110 3z" clip-rule="evenodd" />
                 </svg>
            </h4>
            
            <section id="interactiveChatSection" 
                     class="w-full mx-auto 
                            bg-white rounded-xl sm:rounded-2xl shadow-xl overflow-hidden flex flex-col" 
                     style="display: none; min-height: 400px;"> {/* Added min-height for better visibility when active */}
                <div class="flex-grow overflow-y-auto p-3 sm:p-4 space-y-3" id="chatBoxWrapper"> 
                    <div id="imagePreviewContainer" class="hidden flex flex-col items-center space-y-2 mb-3">
                        <img id="imagePreview" src="#" alt="Image Preview" class="max-w-full h-auto max-h-48 sm:max-h-60 rounded-lg shadow-md border-2 border-gray-200"/>
                        <button id="removeImageBtn" class="text-red-400 hover:text-red-300 text-sm font-medium flex items-center">
                            <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="mr-1"><line x1="18" y1="6" x2="6" y2="18"></line><line x1="6" y1="6" x2="18" y2="18"></line></svg>
                            Remove Image
                        </button>
                    </div>
                    <div id="chatBox" class="space-y-4"> 
                        </div>
                </div>

                <div class="chat-input-bar-container p-2 sm:p-3 border-t border-gray-200">
                    <div id="loadingIndicator" class="hidden text-center pb-2">
                        <div class="flex justify-center items-center"><div class="animate-spin rounded-full h-5 w-5 border-b-2 border-cyan-600"></div><p class="text-cyan-700 ml-2 text-sm">ChatIQ is thinking...</p></div>
                    </div>
                    <div id="errorMessage" class="hidden bg-red-100 text-red-700 p-2 rounded-md text-center mb-2 text-sm"></div>
                    <div class="flex items-center flex-wrap gap-2 sm:gap-3 p-3 bg-gradient-to-r from-cyan-500 to-indigo-600 rounded-xl shadow-lg">
                        <input type="text" id="userInput" placeholder="Ask ChatIQ or describe image..."
                               class="flex-grow min-w-[150px] p-3 rounded-lg text-sm sm:text-base outline-none bg-slate-900/30 text-white placeholder:text-slate-300 focus:ring-2 focus:ring-sky-300 focus:bg-slate-900/40 transition duration-200 ease-in-out backdrop-blur-sm shadow-sm"/>
                        <button id="sendBtn" title="Send Message" class="control-button glassmorphism">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor"><path d="M3.478 2.405a.75.75 0 00-.926.94l2.432 7.905H13.5a.75.75 0 010 1.5H4.984l-2.432 7.905a.75.75 0 00.926.94 60.519 60.519 0 0018.445-8.986.75.75 0 000-1.218A60.517 60.517 0 003.478 2.405z" /></svg>
                        </button>
                        <button id="fileUploadBtn" title="Upload Image" class="control-button glassmorphism">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor"><path d="M16.5 6v11.5c0 2.21-1.79 4-4 4s-4-1.79-4-4V4.5c0-1.38 1.12-2.5 2.5-2.5s2.5 1.12 2.5 2.5V15c0 .55-.45 1-1 1s-1-.45-1-1V6H10v9c0 1.66 1.34 3 3 3s3-1.34 3-3V4.5C16 2.01 13.99 0 11.5 0S7 2.01 7 4.5V15c0 3.04 2.46 5.5 5.5 5.5s5.5-2.46 5.5-5.5V6h-1.5z"></path></svg>
                        </button>
                        <input type="file" id="fileInput" class="hidden" accept="image/*">
                        <button id="cameraBtn" title="Use Camera" class="control-button glassmorphism">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor"><path d="M12 9a3.75 3.75 0 100 7.5A3.75 3.75 0 0012 9z" /><path fill-rule="evenodd" d="M9.344 3.071a49.52 49.52 0 015.312 0c.967.052 1.83.585 2.332 1.39l.821 1.317c.24.383.645.643 1.11.71.386.054.77.113 1.152.177 1.432.239 2.426 1.458 2.426 2.915V19.5a2.25 2.25 0 01-2.25 2.25H5.25a2.25 2.25 0 01-2.25-2.25V9.525c0-1.456.994-2.676 2.426-2.915.382-.064.766-.123 1.152-.177.465-.067.87-.327 1.11-.71l.82-1.318a2.996 2.996 0 012.332-1.39zM12 6.75a5.25 5.25 0 100 10.5 5.25 5.25 0 000-10.5z" clip-rule="evenodd" /></svg>
                        </button>
                        <button id="voiceInputBtn" title="Voice Input" class="control-button glassmorphism">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="mic-icon">
                                <path class="mic-icon-path" fill-rule="evenodd" d="M12.75 3.006a3.75 3.75 0 013.75 3.75v6.75a3.75 3.75 0 01-7.5 0v-6.75a3.75 3.75 0 013.75-3.75zM8.25 8.254a.75.75 0 000 1.5v.75c0 1.657 1.343 3 3 3s3-1.343 3-3v-.75a.75.75 0 000-1.5h-.75a2.25 2.25 0 01-2.25-2.25v-.75a.75.75 0 00-1.5 0v.75A2.25 2.25 0 019 8.254h-.75zM15 13.5a.75.75 0 001.5 0v-2.628A6.002 6.002 0 006.75 8.25v2.628a.75.75 0 001.5 0V8.25c0-.828.672-1.5 1.5-1.5s1.5.672 1.5 1.5v5.25z" clip-rule="evenodd" fill="currentColor"/>
                                <path class="mic-icon-path" d="M6 10.5a.75.75 0 01.75.75v.75a4.5 4.5 0 009 0V11.25a.75.75 0 011.5 0v.75a6 6 0 01-12 0V11.25A.75.75 0 016 10.5zM12 16.5a.75.75 0 00-.75.75v.75h1.5v-.75a.75.75 0 00-.75-.75z" fill="currentColor"/>
                            </svg>
                        </button>
                    </div>
                    <h6 class="text-slate-500 text-center text-xs mt-3 sm:mt-4">ChatIQ can make mistakes. Please recheck and verify information.</h6>
                </div>
            </section>

            <section class="text-center mt-8" id="alternativeVoiceSection" style="display: block;">
                <h2 class="text-2xl font-semibold mb-4">One-to-One Voice Interaction</h2>
                <button onclick="startListeningAdapter()" aria-label="Start Voice Chat with GIF">
                    <img src="https://cdn.dribbble.com/userupload/32122583/file/original-400827bdf243931c8ffd26a268a837ce.gif" alt="Voice Bot Banner" class="mx-auto w-full max-w-md rounded-2xl shadow-lg hover:scale-105 transition-transform"/>
                </button>
                <div class="mt-6">
                    <button onclick="startListeningAdapter()" class="bg-emerald-500 hover:bg-emerald-600 text-white px-6 py-3 rounded-lg shadow-md transition text-lg font-medium flex items-center justify-center mx-auto">
                        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" class="mr-2"><path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3zm7 9a7 7 0 0 1-14 0H3a9 9 0 0 0 8 8.94V22h2v-3.06A9 9 0 0 0 21 10h-2z"></path></svg>
                        Start Voice Chat
                    </button>
                </div>
            </section>
            
            <div id="signInPromptBelowVoiceBot" class="text-center text-gray-600 p-4 mt-2" style="display: block;">
                Please <button id="inlineSignInBtn" class="text-indigo-600 hover:text-indigo-800 font-semibold underline">sign in with Google</button> to use all features and save your chat history.
            </div>
            
            <section id="featuresSection" class="mt-8" style="display: block;">
               <h2 class="text-2xl font-semibold text-center mb-8">Key Features</h2>
                <div class="grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-3 gap-8">
                    <div class="bg-white p-6 rounded-xl shadow-md hover:shadow-xl transition-shadow text-center">
                        <img src="https://img.freepik.com/premium-vector/ai-chat-bot-technology-concept-people-chatting-with-robot-asking-questions-receiving-answers_36358-1867.jpg" 
                             alt="AI Suggestions" class="mx-auto w-36 h-36 object-contain rounded mb-4"
                             onerror="this.onerror=null; this.src='https://placehold.co/144x144/E0E0E0/B0B0B0?text=AI+Feature';">
                        <h3 class="font-semibold text-lg">AI-Powered Suggestions</h3>
                    </div>
                    <div class="bg-white p-6 rounded-xl shadow-md hover:shadow-xl transition-shadow text-center">
                        <img src="https://i.pinimg.com/originals/7d/9b/1d/7d9b1d662b28cd365b33a01a3d0288e1.gif" 
                             alt="Real-Time Voice Chat" class="mx-auto w-36 h-36 object-cover rounded-full mb-4"
                             onerror="this.onerror=null; this.src='https://placehold.co/144x144/E0E0E0/B0B0B0?text=Voice+Chat';">
                        <h3 class="font-semibold text-lg">Real-Time Voice Chat</h3>
                    </div>
                    <div class="bg-white p-6 rounded-xl shadow-md hover:shadow-xl transition-shadow text-center">
                        <img src="https://cdn-icons-png.flaticon.com/512/1048/1048937.png" 
                             alt="Image Recognition" class="mx-auto w-36 h-36 object-contain rounded mb-4"
                             onerror="this.onerror=null; this.src='https://placehold.co/144x144/E0E0E0/B0B0B0?text=Image+AI';">
                        <h3 class="font-semibold text-lg">Image Vision AI</h3>
                    </div>
                </div>
            </section>

            <section id="feedbackSection" class="text-center mt-8" style="display: block;">
                <h2 class="text-2xl font-semibold mb-4">We Value Your Feedback</h2>
                <p class="mb-6 text-gray-600">Help us improve by sharing your thoughts.</p>
                <a href="https://docs.google.com/forms/d/e/1FAIpQLSc2N8OGqdbu2HFbxN4Y89Guv3Wnp9CHLYrz-bzu80kDjHQ3yg/viewform?usp=sharing" target="_blank" class="inline-block bg-gradient-to-r from-indigo-500 to-cyan-400 text-white font-medium px-8 py-3 rounded-full shadow-lg hover:from-indigo-600 hover:to-cyan-500 transition">
                    Give Feedback
                </a>
            </section>
            <footer class="bg-gradient-to-b from-cyan-500 to-indigo-600 text-white py-10 text-center mt-12">
        <h2 class="text-2xl font-bold mb-4">About ChatIQ</h2>
        <p class="max-w-2xl mx-auto mb-6 px-4">ChatIQ assists by providing accurate, real-time answers to your questions through voice, text, and image interactions.</p>
        <div class="space-y-2"><p>📞 <a href="tel:+919369572534" class="hover:underline">+91 93695 72534</a></p><p>✉️ <a href="mailto:ambuj20maurya@gmail.com" class="hover:underline">ambuj20maurya@gmail.com</a></p><p>📍 Mirzapur, Uttar Pradesh, India</p></div>
        <p class="mt-6 text-sm opacity-90">&copy; 2025 ChatIQ. All rights reserved.</p>
    </footer>
        </main>
        
    </div>

    

    <div id="cameraModal" class="fixed top-0 left-0 w-full h-full bg-black/60 hidden items-center justify-center z-[1000]">
        <div class="bg-white p-6 rounded-xl shadow-2xl w-11/12 max-w-md text-center">
            <h3 class="text-xl font-semibold text-gray-700 mb-4">Camera Capture</h3>
            <video id="videoPreviewModal" autoplay playsinline class="w-full max-h-[60vh] rounded-lg mb-4 border border-gray-300 bg-gray-100"></video>
            <div class="flex justify-around mt-4">
                <button id="captureModalBtn" class="bg-green-500 hover:bg-green-600 text-white font-semibold py-2 px-6 rounded-lg transition">Capture</button>
                <button id="closeCameraModalBtn" class="bg-red-500 hover:bg-red-600 text-white font-semibold py-2 px-6 rounded-lg transition">Close</button>
            </div>
        </div>
    </div>

    <script type="module">
        // Firebase Configuration (User Provided - ensure these are correct for your project)
        const firebaseConfig = {
            apiKey: "AIzaSyCEpq8EAkEWbvxGab0wiW9qaYojUdVykyo", 
            authDomain: "chatiq-45203.firebaseapp.com",
            databaseURL: "https://chatiq-45203-default-rtdb.firebaseio.com",
            projectId: "chatiq-45203",
            storageBucket: "chatiq-45203.appspot.com",
            messagingSenderId: "642857846726",
            appId: "1:642857846726:web:f95990ff4f4c37971514c7",
            measurementId: "G-R135XXK005"
        };

        // Firebase Imports
        import { initializeApp, getApps, getApp } from "https://www.gstatic.com/firebasejs/10.12.2/firebase-app.js";
        import { getAuth, GoogleAuthProvider, signInWithPopup, onAuthStateChanged, signOut } from "https://www.gstatic.com/firebasejs/10.12.2/firebase-auth.js";
        import { getFirestore, collection, addDoc, query, orderBy, onSnapshot, serverTimestamp, getDocs, writeBatch, doc, deleteDoc, updateDoc, getDoc } from "https://www.gstatic.com/firebasejs/10.12.2/firebase-firestore.js";
        import { getAnalytics } from "https://www.gstatic.com/firebasejs/10.12.2/firebase-analytics.js";

        // Initialize Firebase
        let app;
        if (!getApps().length) { app = initializeApp(firebaseConfig); } else { app = getApp(); }
        const auth = getAuth(app);
        const db = getFirestore(app);
        const analytics = getAnalytics(app); // Initialize analytics if you plan to use it
        const appIdForPath = firebaseConfig.appId; // Used in Firestore paths for uniqueness

        // DOM Element Variables
        let chatBox, userInput, sendBtn, fileUploadBtn, fileInput, cameraBtn, voiceInputBtn, 
            imagePreviewContainer, imagePreview, removeImageBtn, loadingIndicator, errorMessageDisplay, 
            googleSignInBtnHeader, userDetailsHeaderDiv, userDisplayNameHeaderSpan, signOutBtnHeader, 
            interactiveChatSection, alternativeVoiceSection, swipeDownPromptElement, newChatBtn, 
            signInPromptBelowVoiceBot, inlineSignInBtn, cameraModal, videoPreviewModal, 
            captureModalBtn, closeCameraModalBtn, sessionsListEl, featuresSection, feedbackSection;

        // State Variables
        let currentBase64Image = null, currentMimeType = null, mediaStream = null, 
            speechRecognition = null, isRecording = false, currentBotAudio = null, currentUserId = null;
        
        let activeSessionId = null; 
        let messagesUnsubscribe = null; 
        let sessionsUnsubscribe = null; 

        // API Keys & Endpoints (REPLACE WITH YOUR ACTUAL KEYS)
        const GOOGLE_API_KEY = "AIzaSyC4RwK4x692XDcHZikOaKfpxWHmIXm4kuM"; // <<< IMPORTANT: REPLACE THIS!
        const MURF_API_KEY = "ap2_1ed5cd30-2f51-4ebc-b8f6-33c6a31c81e7";   // <<< IMPORTANT: REPLACE THIS!
        const geminiApiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GOOGLE_API_KEY}`;
        const botPersonaInstructions = `SYSTEM GUIDELINES: You are a smart ChatIQ bot. Aim for concise and precise responses. For simple questions, keep answers to around 5-6 lines or 50 words. For more complex requests, like recipes or explanations, provide a more detailed answer as needed. You are smart and intelligent and can answer any question asked by the user. Answer in a more humanized form, without bullet points or unnecessary special characters unless the format is essential for clarity (like in a recipe's steps). When a user asks "who are you", respond: 'I am a smart ChatIQ bot.' If the user asks about "your name", respond: 'I am a smart ChatIQ bot.' If the user asks "who made you", respond: 'I was made by ChatIQ.' --- User's request is below. If the user's message specifically asks one of the predefined questions above (who are you, your name, who made you), use ONLY the predefined answer. Otherwise, answer their question following all the general persona guidelines. If an image is provided, consider it in your response along with the text.`;

        // --- Utility Functions ---
        function showError(messageText) { 
            console.error("ChatIQ Error:", messageText); // Log error to console for debugging
            const errorElement = document.getElementById('errorMessage');
            if (errorElement) {
                errorElement.textContent = messageText; 
                errorElement.classList.remove('hidden');
                setTimeout(() => { errorElement.classList.add('hidden'); }, 5000);
            } else { 
                // Fallback if error message display element isn't found early
                alert("Notice: " + messageText); 
            }
        }
        
        // --- DOMContentLoaded: Initialize after page loads ---
        document.addEventListener('DOMContentLoaded', () => {
            // Assign all DOM Elements
            chatBox = document.getElementById('chatBox'); 
            userInput = document.getElementById('userInput'); 
            sendBtn = document.getElementById('sendBtn');
            fileUploadBtn = document.getElementById('fileUploadBtn'); 
            fileInput = document.getElementById('fileInput'); 
            cameraBtn = document.getElementById('cameraBtn');
            voiceInputBtn = document.getElementById('voiceInputBtn'); 
            imagePreviewContainer = document.getElementById('imagePreviewContainer');
            imagePreview = document.getElementById('imagePreview'); 
            removeImageBtn = document.getElementById('removeImageBtn');
            loadingIndicator = document.getElementById('loadingIndicator'); 
            errorMessageDisplay = document.getElementById('errorMessage'); 
            googleSignInBtnHeader = document.getElementById('googleSignInBtnHeader');
            userDetailsHeaderDiv = document.getElementById('userDetailsHeader');
            userDisplayNameHeaderSpan = document.getElementById('userDisplayNameHeader');
            signOutBtnHeader = document.getElementById('signOutBtnHeader');
            interactiveChatSection = document.getElementById('interactiveChatSection');
            alternativeVoiceSection = document.getElementById('alternativeVoiceSection');
            swipeDownPromptElement = document.getElementById('swipeDownPrompt');
            newChatBtn = document.getElementById('newChatBtn');
            signInPromptBelowVoiceBot = document.getElementById('signInPromptBelowVoiceBot');
            inlineSignInBtn = document.getElementById('inlineSignInBtn');
            cameraModal = document.getElementById('cameraModal');
            videoPreviewModal = document.getElementById('videoPreviewModal');
            captureModalBtn = document.getElementById('captureModalBtn');
            closeCameraModalBtn = document.getElementById('closeCameraModalBtn');
            sessionsListEl = document.getElementById('sessionsList');
            featuresSection = document.getElementById('featuresSection');
            feedbackSection = document.getElementById('feedbackSection');

            // Check for placeholder API keys
            if(GOOGLE_API_KEY === "YOUR_GEMINI_API_KEY" || MURF_API_KEY === "YOUR_MURF_API_KEY"){
                showError("CRITICAL: Placeholder API keys detected. Please update them in the script for ChatIQ to function correctly.");
            }
            
            initializeSpeechRecognition(); 
            setupEventListeners();
            setupAuthListener(); // This will also handle initial UI setup based on auth state
        });
        
        // --- Event Listener Setup ---
        function setupEventListeners() { 
            // Ensure elements exist before adding listeners to prevent errors
            if(googleSignInBtnHeader) googleSignInBtnHeader.addEventListener('click', signInWithGoogle);
            if(signOutBtnHeader) signOutBtnHeader.addEventListener('click', signOutUser);
            if(newChatBtn) newChatBtn.addEventListener('click', startNewChatSession);
            if(inlineSignInBtn) inlineSignInBtn.addEventListener('click', signInWithGoogle); 

            if(sendBtn) sendBtn.addEventListener('click', handleSendMessageWrapper);
            if(userInput) userInput.addEventListener('keypress', (e) => { 
                if (e.key === 'Enter' && !e.shiftKey) { 
                    e.preventDefault(); 
                    handleSendMessageWrapper(); 
                }
            });
            if(fileUploadBtn) fileUploadBtn.addEventListener('click', () => fileInput.click());
            if(fileInput) fileInput.addEventListener('change', handleFileSelect);
            if(removeImageBtn) removeImageBtn.addEventListener('click', removeImagePreview);
            
            if(cameraBtn) cameraBtn.addEventListener('click', openCameraModal); 
            if(captureModalBtn) captureModalBtn.addEventListener('click', captureImageFromModal);
            if(closeCameraModalBtn) closeCameraModalBtn.addEventListener('click', closeCameraModalAndStream);

            if(voiceInputBtn) voiceInputBtn.addEventListener('click', toggleVoiceInput);
        }

        // --- Firebase Authentication ---
        async function signInWithGoogle() { 
            if (!auth) { showError("Firebase Auth service is not available."); return; }
            const provider = new GoogleAuthProvider();
            try { 
                await signInWithPopup(auth, provider); 
                // onAuthStateChanged will handle UI updates
            } 
            catch (error) { 
                console.error("Google Sign-In Error:", error); 
                showError(`Google Sign-In Failed: ${error.message} (Code: ${error.code})`); 
            }
        }

        async function signOutUser() { 
            if (!auth) { showError("Firebase Auth service is not available."); return; }
            try { 
                await signOut(auth); 
                activeSessionId = null; 
                if(sessionsListEl) sessionsListEl.innerHTML = ''; 
                if(chatBox) chatBox.innerHTML = '';
                // onAuthStateChanged will handle UI updates
            } 
            catch (error) { 
                console.error("Sign Out Error:", error); 
                showError("Error signing out: " + error.message); 
            }
        }

        function setupAuthListener() { 
            if (!auth) { 
                console.error("Firebase Auth not initialized for listener. Cannot set up auth state changes."); 
                showError("Critical: Authentication service is not ready. Please refresh."); 
                // Display a very basic logged-out state if auth fails to initialize
                if(interactiveChatSection) interactiveChatSection.style.display = 'none';
                if(alternativeVoiceSection) alternativeVoiceSection.style.display = 'block';
                if(signInPromptBelowVoiceBot) signInPromptBelowVoiceBot.style.display = 'block';
                if(featuresSection) featuresSection.style.display = 'block';
                if(feedbackSection) feedbackSection.style.display = 'block';
                if(googleSignInBtnHeader) googleSignInBtnHeader.style.display = 'inline-block';
                if(userDetailsHeaderDiv) userDetailsHeaderDiv.style.display = 'none';
                if(newChatBtn) newChatBtn.style.display = 'none';
                return; 
            }

            const chatHistorySidebar = document.getElementById('chatHistorySidebar');
            onAuthStateChanged(auth, (user) => {
                if (user) { // User is signed in
                    currentUserId = user.uid;
                    if(userDisplayNameHeaderSpan) userDisplayNameHeaderSpan.textContent = `Hi, ${user.displayName || user.email.split('@')[0] || 'User'}!`;
                    if(googleSignInBtnHeader) googleSignInBtnHeader.style.display = 'none';
                    if(newChatBtn) newChatBtn.style.display = 'inline-block'; 
                    if(userDetailsHeaderDiv) userDetailsHeaderDiv.style.display = 'flex';
                    
                    // Show chat, hide alternatives
                    if(interactiveChatSection) interactiveChatSection.style.display = 'flex'; // Use flex for chat layout
                    if(alternativeVoiceSection) alternativeVoiceSection.style.display = 'none'; 
                    if(signInPromptBelowVoiceBot) signInPromptBelowVoiceBot.style.display = 'none';
                    if(featuresSection) featuresSection.style.display = 'none'; // Hide features when signed in
                    if(feedbackSection) feedbackSection.style.display = 'none'; // Hide feedback when signed in

                    if(swipeDownPromptElement) swipeDownPromptElement.style.display = 'inline-flex'; // Or 'block' if preferred
                    if(chatHistorySidebar) {
                        chatHistorySidebar.classList.remove('hidden'); 
                        chatHistorySidebar.classList.add('flex');
                    }
                    loadChatSessions(); 
                } else { // User is signed out
                    currentUserId = null; 
                    activeSessionId = null;
                    if(userDisplayNameHeaderSpan) userDisplayNameHeaderSpan.textContent = '';
                    if(googleSignInBtnHeader) googleSignInBtnHeader.style.display = 'inline-block';
                    if(newChatBtn) newChatBtn.style.display = 'none'; 
                    if(userDetailsHeaderDiv) userDetailsHeaderDiv.style.display = 'none';

                    // Hide chat, show alternatives and info sections
                    if(interactiveChatSection) interactiveChatSection.style.display = 'none';
                    if(alternativeVoiceSection) alternativeVoiceSection.style.display = 'block';
                    if(signInPromptBelowVoiceBot) signInPromptBelowVoiceBot.style.display = 'block';
                    if(featuresSection) featuresSection.style.display = 'block'; // Show features when signed out
                    if(feedbackSection) feedbackSection.style.display = 'block'; // Show feedback when signed out


                    if(swipeDownPromptElement) swipeDownPromptElement.style.display = 'none';
                    if(chatHistorySidebar) {
                        chatHistorySidebar.classList.add('hidden');
                        chatHistorySidebar.classList.remove('flex');
                    }

                    if(messagesUnsubscribe) messagesUnsubscribe(); 
                    if(sessionsUnsubscribe) sessionsUnsubscribe();
                    if(chatBox) chatBox.innerHTML = '<div class="text-center text-gray-500 p-4">Please sign in with Google to use ChatIQ and see your history.</div>';
                    if(sessionsListEl) sessionsListEl.innerHTML = '';
                }
            });
        }
        
        // --- Chat Session Management (Firestore) ---
        async function startNewChatSession() {
            if (!currentUserId || !db) { showError("Please sign in to start a new chat."); return; }
            console.log("Starting new chat session for user:", currentUserId);
            const newSessionName = `Chat ${new Date().toLocaleString()}`; 
            try {
                const sessionsColPath = `artifacts/${appIdForPath}/users/${currentUserId}/sessions`;
                const sessionRef = await addDoc(collection(db, sessionsColPath), {
                    title: newSessionName,
                    createdAt: serverTimestamp(),
                    lastActivity: serverTimestamp() // Initialize lastActivity
                });
                activeSessionId = sessionRef.id;
                console.log("New session created with ID:", activeSessionId);
                if (chatBox) chatBox.innerHTML = ''; 
                loadChatHistory(activeSessionId); // This will also handle the welcome message for new chats
                // loadChatSessions() will update the sidebar via its onSnapshot listener
            } catch (error) {
                console.error("Error creating new session:", error);
                showError("Could not start a new chat session. Firestore error: " + error.message);
            }
        }

        async function deleteSession(sessionIdToDelete) {
            if (!currentUserId || !db || !sessionIdToDelete) {
                showError("Cannot delete session: missing user, database, or session ID.");
                return;
            }
            console.log(`Attempting to delete session: ${sessionIdToDelete} for user: ${currentUserId}`);
            
            // Using a custom modal for confirmation is better, but confirm() is simpler for now.
            // In a real app, replace confirm() with a custom UI modal.
            const confirmed = window.confirm("Are you sure you want to delete this chat session and all its messages permanently?");
            if (!confirmed) return;

            try {
                // 1. Delete all messages in the subcollection
                const messagesPath = `artifacts/${appIdForPath}/users/${currentUserId}/sessions/${sessionIdToDelete}/messages`;
                const messagesQuery = query(collection(db, messagesPath));
                const messagesSnapshot = await getDocs(messagesQuery);
                const batch = writeBatch(db);
                messagesSnapshot.forEach(docMsg => { // Renamed doc to docMsg to avoid conflict
                    batch.delete(docMsg.ref);
                });
                await batch.commit();
                console.log(`Messages for session ${sessionIdToDelete} deleted.`);

                // 2. Delete the session document itself
                const sessionDocPath = `artifacts/${appIdForPath}/users/${currentUserId}/sessions/${sessionIdToDelete}`;
                await deleteDoc(doc(db, sessionDocPath)); 
                console.log(`Session ${sessionIdToDelete} metadata deleted.`);

                if (activeSessionId === sessionIdToDelete) {
                    activeSessionId = null;
                    if (chatBox) chatBox.innerHTML = '<div class="text-center text-gray-500 p-4">Session deleted. Start a new chat or select another from the history.</div>';
                    // Attempt to load the next available session or prompt to start new
                    const sessionItems = sessionsListEl.querySelectorAll('.session-item');
                    if (sessionItems.length > 0) {
                        selectSession(sessionItems[0].dataset.sessionId); // Select the first one in the list (most recent)
                    } else {
                        startNewChatSession(); // If no sessions left, start a new one
                    }
                }
                // loadChatSessions() will refresh the list via its onSnapshot, which is good.
            } catch (error) {
                console.error(`Error deleting session ${sessionIdToDelete}:`, error);
                showError("Failed to delete chat session. Firestore error: " + error.message);
            }
        }

        function loadChatSessions() {
            if (!currentUserId || !db || !sessionsListEl) {
                console.warn("Cannot load chat sessions: missing user, DB, or sessions list element.");
                if (sessionsListEl) sessionsListEl.innerHTML = '<li class="text-xs text-gray-400 p-2">Sign in to see history.</li>';
                return;
            }
            if (sessionsUnsubscribe) sessionsUnsubscribe(); // Unsubscribe from previous listener

            const sessionsColPath = `artifacts/${appIdForPath}/users/${currentUserId}/sessions`;
            const q = query(collection(db, sessionsColPath), orderBy("lastActivity", "desc")); // Order by lastActivity

            sessionsUnsubscribe = onSnapshot(q, (snapshot) => {
                if (!sessionsListEl) return;
                sessionsListEl.innerHTML = ''; 
                let firstSessionIdFromSnapshot = null;
                let sessionCount = 0;

                if (snapshot.empty) {
                    sessionsListEl.innerHTML = '<div class="text-xs text-gray-400 p-2 text-center">No chat history yet. Start a new chat!</div>';
                    if (!activeSessionId) { // If no active session and history is empty, start a new one
                        startNewChatSession();
                    }
                    return;
                }

                snapshot.forEach((docSnap) => {
                    sessionCount++;
                    const session = docSnap.data();
                    const sessionId = docSnap.id;
                    if (!firstSessionIdFromSnapshot) firstSessionIdFromSnapshot = sessionId; 

                    const item = document.createElement('div');
                    item.dataset.sessionId = sessionId; 
                    item.classList.add('session-item', 'p-2', 'rounded-md', 'cursor-pointer', 'text-sm', 'text-slate-700', 'flex', 'justify-between', 'items-center', 'hover:bg-slate-100');
                    if (sessionId === activeSessionId) {
                        item.classList.add('active', 'bg-blue-100', 'text-blue-700'); // Ensure active class is visually distinct
                    }
                    
                    const titleSpan = document.createElement('span');
                    titleSpan.textContent = session.title || `Chat from ${session.createdAt?.toDate().toLocaleDateString() || 'Unknown date'}`;
                    titleSpan.classList.add('truncate', 'flex-1', 'mr-2');
                    item.appendChild(titleSpan);

                    const deleteBtn = document.createElement('button');
                    deleteBtn.innerHTML = '&times;'; 
                    deleteBtn.classList.add('text-red-400', 'hover:text-red-600', 'font-bold', 'px-2', 'py-1', 'rounded', 'hover:bg-red-100', 'transition-colors');
                    deleteBtn.title = "Delete this chat session";
                    deleteBtn.onclick = (event) => {
                        event.stopPropagation(); 
                        deleteSession(sessionId);
                    };
                    item.appendChild(deleteBtn);
                    
                    item.onclick = () => selectSession(sessionId);
                    sessionsListEl.appendChild(item);
                });

                // If no session is currently active, and there are sessions, select the most recent one.
                if (sessionCount > 0 && !activeSessionId && firstSessionIdFromSnapshot) { 
                    selectSession(firstSessionIdFromSnapshot);
                } else if (sessionCount > 0 && activeSessionId) {
                    // Ensure the active session is still highlighted if the list re-renders
                    const currentActiveItem = sessionsListEl.querySelector(`.session-item[data-session-id="${activeSessionId}"]`);
                    if (currentActiveItem && !currentActiveItem.classList.contains('active')) {
                        currentActiveItem.classList.add('active', 'bg-blue-100', 'text-blue-700');
                    }
                }

            }, (error) => {
                console.error("Error loading chat sessions:", error);
                showError("Could not load chat sessions. Firestore error: " + error.message);
                if (sessionsListEl) sessionsListEl.innerHTML = '<li class="text-xs text-red-500 p-2">Error loading history.</li>';
            });
        }
        
        function selectSession(sessionId) {
            if (!sessionId) {
                console.warn("Attempted to select a null/undefined session ID.");
                return;
            }
            // Only proceed if changing session or if chatbox indicates it's not loaded for current active session
            if (activeSessionId === sessionId && chatBox && !chatBox.innerHTML.includes('Loading chat...')) return; 

            console.log("Selecting session:", sessionId);
            activeSessionId = sessionId;
            if (messagesUnsubscribe) messagesUnsubscribe(); 
            if (chatBox) chatBox.innerHTML = '<div class="text-center text-gray-400 p-4">Loading chat...</div>'; 
            loadChatHistory(activeSessionId);

            // Update active class in sidebar
            if (sessionsListEl) {
                const sessionItems = sessionsListEl.querySelectorAll('.session-item');
                sessionItems.forEach(item => {
                    if (item.dataset.sessionId === sessionId) {
                        item.classList.add('active', 'bg-blue-100', 'text-blue-700');
                    } else {
                        item.classList.remove('active', 'bg-blue-100', 'text-blue-700');
                    }
                });
            }
        }

        // --- Message Handling (Firestore & UI) ---
        async function saveMessageToFirestore(messageData) { 
            if (!currentUserId || !activeSessionId) { 
                showError("Cannot save message: Not signed in or no active chat session."); 
                return; 
            }
            if (!db) {
                showError("Cannot save message: Database service not available.");
                return;
            }
            try { 
                const messagesColPath = `artifacts/${appIdForPath}/users/${currentUserId}/sessions/${activeSessionId}/messages`; 
                await addDoc(collection(db, messagesColPath), { 
                    ...messageData, 
                    userId: currentUserId, // Ensure userId is part of the message data
                    timestamp: serverTimestamp() 
                }); 
                
                // Update session's lastActivity and potentially title
                const sessionDocPath = `artifacts/${appIdForPath}/users/${currentUserId}/sessions/${activeSessionId}`;
                const sessionDocRef = doc(db, sessionDocPath);
                const sessionSnap = await getDoc(sessionDocRef); 

                if (sessionSnap.exists()) {
                    const sessionData = sessionSnap.data();
                    let updateData = { lastActivity: serverTimestamp() };

                    // Update title only if it's the very first user text message and title is default-like
                    if (messageData.sender === 'user' && messageData.type === 'text' && messageData.content) {
                        const messagesQuery = query(collection(db, messagesColPath), orderBy("timestamp", "asc"));
                        const existingMessagesSnap = await getDocs(messagesQuery);
                        let userTextMessagesCount = 0;
                        existingMessagesSnap.forEach(msgDoc => {
                            if (msgDoc.data().sender === 'user' && msgDoc.data().type === 'text') {
                                userTextMessagesCount++;
                            }
                        });

                        if (userTextMessagesCount === 1 && sessionData.title && sessionData.title.startsWith("Chat ")) { 
                           updateData.title = messageData.content.substring(0, 35) + (messageData.content.length > 35 ? '...' : '');
                        }
                    }
                    await updateDoc(sessionDocRef, updateData); 
                }
            } 
            catch (error) { 
                console.error("Error saving message to Firestore:", error); 
                showError("Error saving message. Firestore error: " + error.message); 
            }
        }

        function loadChatHistory(sessionIdToLoad) { 
            if (!db || !chatBox || !sessionIdToLoad || !currentUserId) { 
                if(chatBox) chatBox.innerHTML = '<div class="text-center text-gray-500 p-4">Select a chat or start a new one to see messages.</div>';
                console.warn("Cannot load chat history: missing DB, chatBox, session ID, or user ID.");
                return; 
            }
            if (messagesUnsubscribe) messagesUnsubscribe(); // Unsubscribe from previous listener
            
            const messagesColPath = `artifacts/${appIdForPath}/users/${currentUserId}/sessions/${sessionIdToLoad}/messages`;
            const q = query(collection(db, messagesColPath), orderBy("timestamp", "asc")); 
            
            chatBox.innerHTML = ''; // Clear chatbox before loading new messages
            let initialWelcomeMessageAdded = false;

            messagesUnsubscribe = onSnapshot(q, (snapshot) => {
                if (!chatBox) return;
                chatBox.innerHTML = ''; // Clear and re-render all messages on each snapshot for simplicity
                let messageCount = 0;
                snapshot.forEach((docMsg) => { 
                    messageCount++;  
                    const msg = docMsg.data();  
                    if (msg.type === 'image') {
                        addImageToChatLog(msg.content, msg.mimeType, msg.sender);  
                    } else {
                        addMessageToChat(msg.content, msg.sender);  
                    }
                });

                if (messageCount === 0 && !snapshot.metadata.hasPendingWrites && !initialWelcomeMessageAdded) {  
                     const welcomeMessage = "Chat started! How can I assist you today?";  
                     addMessageToChat(welcomeMessage, "bot");
                     // This welcome message is UI only for new chats, not saved to DB.
                     initialWelcomeMessageAdded = true;  
                }
                if(chatBox) chatBox.scrollTop = chatBox.scrollHeight; 
            }, (error) => { 
                console.error(`Error loading messages for session ${sessionIdToLoad}:`, error); 
                showError("Failed to load messages. Firestore error: " + error.message); 
                if (chatBox) chatBox.innerHTML = `<div class="text-center text-red-500 p-4">Error loading messages.</div>`;
            });
        }
        
        function addMessageToChat(text, sender) { 
            if (!chatBox) { console.warn("addMessageToChat: chatBox element not found."); return; }
            const messageDiv = document.createElement('div'); 
            messageDiv.classList.add('flex', sender === 'user' ? 'justify-end' : 'justify-start', 'w-full', 'py-1'); 
            const bubbleDiv = document.createElement('div'); 
            bubbleDiv.classList.add(sender === 'user' ? 'chat-bubble-user' : 'chat-bubble-bot'); 
            
            // Handle code blocks (Markdown-like ``` ```)
            const codeBlockRegex = /```(\w*)\n([\s\S]*?)\n```/gm; 
            let lastIndex = 0; 
            let hasCodeBlock = false; 
            const contentFragment = document.createDocumentFragment(); 

            text.replace(codeBlockRegex, (match, lang, codeContent, offset) => { 
                hasCodeBlock = true; 
                if (offset > lastIndex) { 
                    contentFragment.appendChild(document.createTextNode(text.substring(lastIndex, offset))); 
                } 
                const preElement = document.createElement('pre'); 
                const codeElement = document.createElement('code'); 
                if (lang) codeElement.classList.add(`language-${lang}`); 
                codeElement.textContent = codeContent.trim(); 
                preElement.appendChild(codeElement); 
                contentFragment.appendChild(preElement); 
                lastIndex = offset + match.length; 
                return match; // Required by .replace
            }); 

            if (lastIndex < text.length) { 
                contentFragment.appendChild(document.createTextNode(text.substring(lastIndex))); 
            } 

            if (contentFragment.hasChildNodes()) { 
                bubbleDiv.appendChild(contentFragment); 
            } else if (!hasCodeBlock) { // Fallback for simple text if no code blocks were processed
                bubbleDiv.textContent = text; 
            }
            
            messageDiv.appendChild(bubbleDiv); 
            chatBox.appendChild(messageDiv); 
            if(chatBox) chatBox.scrollTop = chatBox.scrollHeight; 
        }

        function addImageToChatLog(base64, mime, sender) { 
            if (!chatBox) { console.warn("addImageToChatLog: chatBox element not found."); return; }
            const div = document.createElement('div'); 
            div.classList.add('flex', sender === 'user' ? 'justify-end' : 'justify-start', 'w-full', 'my-1'); 
            const bubble = document.createElement('div'); 
            bubble.classList.add('image-chat-bubble'); 
            bubble.style.backgroundColor = sender === 'user' ? '#DBEAFE' : '#D1FAE5'; 
            const img = document.createElement('img'); 
            img.src = `data:${mime};base64,${base64}`; 
            img.alt = sender === 'user' ? "User uploaded image" : "Bot generated image"; 
            bubble.appendChild(img); 
            div.appendChild(bubble); 
            chatBox.appendChild(div); 
            if(chatBox) chatBox.scrollTop = chatBox.scrollHeight; 
        }
        
        function showLoading(isLoading) { 
            if(!loadingIndicator) { console.warn("showLoading: loadingIndicator element not found."); return; }
            loadingIndicator.classList.toggle('hidden', !isLoading); 
        }

        // --- Send Message Wrapper & Core Logic ---
        async function handleSendMessageWrapper() { 
            if (!userInput || !chatBox ) { showError("Chat interface is not ready."); return; }
            if (!currentUserId || !activeSessionId) { showError("Please sign in and select or start a chat session to send messages."); return; } 
            await handleSendMessage(); 
        }

        async function handleSendMessage() { 
            const textContent = userInput.value.trim(); 
            const imageBase64 = currentBase64Image; // Use a different variable name to avoid confusion
            const imageMimeType = currentMimeType;
            
            if (!textContent && !imageBase64) { 
                showError("Please type a message, speak, or upload an image to send."); 
                return; 
            }
            if (!activeSessionId) { 
                showError("No active chat session. Please start or select a chat from history."); 
                return; 
            }

            // Save user's image message (if any)
            if (imageBase64 && imageMimeType) {
                await saveMessageToFirestore({ sender: 'user', type: 'image', content: imageBase64, mimeType: imageMimeType });
            }
            // Save user's text message (if any)
            if (textContent) {
                await saveMessageToFirestore({ sender: 'user', type: 'text', content: textContent });
            }
            
            if(userInput) userInput.value = ''; 
            removeImagePreview(); // Clear image preview after sending
            showLoading(true); // Show loading indicator

            // Basic vulgarity check (replace with a more robust solution if needed)
            if (textContent && containsVulgar(textContent)) { 
                const vulgarResponseMessage = "I cannot assist with requests containing inappropriate language."; 
                // addMessageToChat(vulgarResponseMessage, "bot"); // UI updated by Firestore listener
                await saveMessageToFirestore({ sender: 'bot', type: 'text', content: vulgarResponseMessage }); 
                showLoading(false); 
                speakResponse(vulgarResponseMessage); 
                return; 
            }

            // Prepare payload for Gemini API
            try {
                let geminiParts = []; 
                let combinedPromptForGemini = botPersonaInstructions; // Start with system instructions

                if (textContent) {
                    combinedPromptForGemini += "\n\nUSER QUERY TEXT: " + textContent;
                } else if (imageBase64 && !textContent) {
                    combinedPromptForGemini += "\n\nUSER QUERY TEXT: (No text provided, please analyze the following image)";
                }
                geminiParts.push({ text: combinedPromptForGemini }); 
                
                if (imageBase64 && imageMimeType) {
                    geminiParts.push({ inlineData: { mimeType: imageMimeType, data: imageBase64 } });
                }
                
                const payload = { contents: [{ role: "user", parts: geminiParts }] };
                
                const response = await fetch(geminiApiUrl, { 
                    method: 'POST', 
                    headers: { 'Content-Type': 'application/json' }, 
                    body: JSON.stringify(payload) 
                });
                
                let botResponseText = "Sorry, I encountered an issue processing your request."; // Default error message
                if (!response.ok) { 
                    const errorData = await response.json().catch(()=>({error:{message:"API error with non-JSON response or parsing failed"}})); 
                    botResponseText = `API Error (${response.status}): ${errorData.error?.message || response.statusText || "Unknown API error"}`; 
                    if (response.status === 429) botResponseText = "API rate limit exceeded. Please try again in a few moments.";
                    console.error("Gemini API Error:", botResponseText, errorData);
                } else { 
                    const result = await response.json(); 
                    if (result.candidates && result.candidates[0] && result.candidates[0].content && result.candidates[0].content.parts && result.candidates[0].content.parts[0] && result.candidates[0].content.parts[0].text) {
                        botResponseText = result.candidates[0].content.parts[0].text;
                    } else if (result.promptFeedback && result.promptFeedback.blockReason) {
                        botResponseText = `Your request was blocked by the AI for the following reason: ${result.promptFeedback.blockReason}. This may be due to safety settings or content policy.`;
                        console.warn("Gemini API Blocked:", result.promptFeedback);
                    } else if (result.candidates && result.candidates[0] && result.candidates[0].finishReason && result.candidates[0].finishReason !== "STOP") {
                        botResponseText = `The AI stopped responding due to: ${result.candidates[0].finishReason}. This might be due to safety settings, length limitations, or other factors.`;
                        console.warn("Gemini API Finish Reason:", result.candidates[0].finishReason);
                    } else {
                        console.warn("Gemini API - Unexpected response structure:", result);
                    }
                }
                // addMessageToChat(botResponseText, 'bot'); // UI update handled by Firestore listener
                await saveMessageToFirestore({ sender: 'bot', type: 'text', content: botResponseText }); 
                speakResponse(botResponseText);
            } catch (error) { 
                console.error('Error during Gemini API call or processing:', error); 
                let detailedErrorMessage = `An unexpected error occurred: ${error.message}`;
                showError(detailedErrorMessage); 
                // addMessageToChat(detailedErrorMessage, 'bot'); // UI update handled by Firestore listener
                await saveMessageToFirestore({ sender: 'bot', type: 'text', content: detailedErrorMessage });
            } finally { 
                showLoading(false); 
            }
        }

        // --- Speech Recognition (STT) & Synthesis (TTS) ---
        function initializeSpeechRecognition() { 
            const SpeechRecognitionAPI = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (SpeechRecognitionAPI) { 
                speechRecognition = new SpeechRecognitionAPI(); 
                speechRecognition.continuous = false; // Stop after first recognized phrase
                speechRecognition.lang = 'en-US'; // Default language, can be changed
                speechRecognition.interimResults = false; 
                speechRecognition.maxAlternatives = 1;
                
                speechRecognition.onresult = (event) => { 
                    const transcript = event.results[0][0].transcript.trim(); 
                    if(userInput) userInput.value = transcript; 
                    stopRecording(); // UI update for button
                    if(transcript) {
                        handleSendMessageWrapper(); // Send the recognized text
                    } else {
                        showError("Voice input was empty or not recognized.");
                    }
                };
                speechRecognition.onerror = (event) => { 
                    let errorMessage = `Speech recognition error: ${event.error}.`; 
                    if(event.error === 'no-speech') errorMessage = "No speech was detected. Please try speaking clearly."; 
                    else if(event.error === 'audio-capture') errorMessage = "Microphone error. Please check your microphone connection and permissions."; 
                    else if(event.error === 'not-allowed') errorMessage = "Microphone access denied. Please allow microphone access in your browser settings."; 
                    else if(event.error === 'language-not-supported') errorMessage = `The language '${speechRecognition.lang}' is not supported for speech recognition.`;
                    showError(errorMessage); 
                    stopRecording(); 
                };
                speechRecognition.onend = () => { 
                    // Ensure recording state is correctly updated if recognition ends unexpectedly
                    if (isRecording) stopRecording(); 
                };
            } else { 
                if(voiceInputBtn) voiceInputBtn.disabled = true; 
                showError('Speech recognition (voice input) is not supported by your browser.'); 
                console.warn("SpeechRecognition API not available.");
            }
        }

        async function getMurfAudioUrl(textToSpeak, languageCode = 'en-US') { 
            if (!MURF_API_KEY || MURF_API_KEY==="YOUR_MURF_API_KEY" ) { 
                console.warn("Murf API key is a placeholder or invalid. Skipping Murf TTS."); 
                return null; 
            }
            // Murf voice configuration (examples, check Murf documentation for available voices)
            const voiceConfig = {
                'en-US': { voice: 'en-US-ryan', style: 'conversational', mood: 'neutral' }, // Example Murf voice
                'hi-IN': { voice: 'hi-IN-Diksha', style: 'conversational', mood: 'neutral' } // Example Murf voice for Hindi
            };
            const selectedVoice = voiceConfig[languageCode] || voiceConfig['en-US']; // Default to en-US
            
            const murfApiUrl = "https://api.murf.ai/v1/speech/generate"; // Murf V1 endpoint
            const payload = {
                text: textToSpeak, 
                voice: selectedVoice.voice, 
                style: selectedVoice.style, 
                mood: selectedVoice.mood,
                format: "mp3", 
                sampleRate: 24000, // Common sample rate for good quality
                convertToSsml: true // Let Murf handle SSML conversion if needed
            };
            
            try { 
                const response = await fetch(murfApiUrl, {
                    method: "POST",
                    headers: {
                        "api-key": MURF_API_KEY,
                        // "X-Project-Id": "YOUR_MURF_PROJECT_ID_IF_ANY", // Add if you use specific Murf projects
                        "Content-Type": "application/json"
                    },
                    body: JSON.stringify(payload)
                }); 
                const data = await response.json();
                if(!response.ok){
                    showError(`Murf API Error (${response.status}): ${data.message || 'Unknown error'}. Voice: ${selectedVoice.voice}`);
                    console.error("Murf API Error:", data);
                    return null;
                } 
                if(!data.audioFile){ // 'audioFile' is typical for Murf V1
                    showError(`Murf API Error: No audioFile in response. ${data.message || ''}`);
                    console.error("Murf API - No audioFile:", data);
                    return null;
                } 
                return data.audioFile; 
            } catch(err){
                showError(`Murf API Request Exception: ${err.message}.`);
                console.error("Murf API Exception:", err);
                return null;
            }
        }

        async function speakResponse(textToSpeak) { 
            // Stop any currently playing bot audio or browser speech
            if(currentBotAudio && !currentBotAudio.paused) currentBotAudio.pause(); 
            if('speechSynthesis' in window) window.speechSynthesis.cancel(); 

            let languageCode = 'en-US'; // Default
            if(/[\u0900-\u097F]/.test(textToSpeak)) languageCode = 'hi-IN'; // Basic check for Hindi characters

            let spokenViaMurf = false;
            const murfAudioUrl = await getMurfAudioUrl(textToSpeak, languageCode); 
            if(murfAudioUrl){
                try{
                    currentBotAudio = new Audio(murfAudioUrl);
                    await currentBotAudio.play();
                    spokenViaMurf = true;
                } catch(e){
                    console.error("Murf audio playback error:", e);
                    currentBotAudio = null; // Reset if playback fails
                }
            }
            
            // Fallback to browser's built-in TTS if Murf fails or is not used
            if(!spokenViaMurf && 'speechSynthesis' in window){
                const utterance = new SpeechSynthesisUtterance(textToSpeak); 
                utterance.lang = languageCode; 
                try { 
                    const voices = window.speechSynthesis.getVoices(); 
                    if(voices.length > 0){
                        const voiceForLang = voices.find(v => v.lang === languageCode);
                        if(voiceForLang) utterance.voice = voiceForLang;
                    } 
                } catch(e) { 
                    console.warn("Could not get/set voices for browser TTS:", e); 
                }
                window.speechSynthesis.speak(utterance);
            } else if (!spokenViaMurf) {
                console.warn('Text-to-speech is not available (neither Murf nor browser TTS).');
            }
        }

        function toggleVoiceInput(){ 
            if(!speechRecognition){ showError('Voice input (speech recognition) is not available in your browser.'); return; }
            if(isRecording) stopRecording(); else startRecording();
        }

        function startRecording() { 
            if (!speechRecognition) { showError("Speech recognition not initialized."); return; }
            try { 
                if(userInput) userInput.value = ""; // Clear input field
                if(currentBotAudio && !currentBotAudio.paused) currentBotAudio.pause(); // Stop TTS
                if('speechSynthesis' in window) window.speechSynthesis.cancel(); // Cancel any browser speech

                speechRecognition.start();
                isRecording = true; 
                if(voiceInputBtn) { 
                    voiceInputBtn.classList.add('recording'); 
                    voiceInputBtn.title = "Stop Recording"; 
                    // Visual feedback for recording (e.g., change icon color) handled by CSS .recording class
                }
            }
            catch(e){
                if(e.name === 'InvalidStateError'){ 
                    // This can happen if stopRecording was called right before, or already recording.
                    // Usually means it's already trying to stop or start.
                    console.warn("Speech recognition InvalidStateError on start, likely already stopping/starting.");
                    stopRecording(); // Ensure it's reset
                } else {
                    showError("Could not start voice recording: " + e.message); 
                    isRecording = false; 
                    if(voiceInputBtn) { 
                        voiceInputBtn.classList.remove('recording'); 
                        voiceInputBtn.title = "Voice Input"; 
                    }
                }
            }
        }

        function stopRecording(){ 
            if(speechRecognition && isRecording) {
                try {
                    speechRecognition.stop();
                } catch (e) {
                    console.warn("Error stopping speech recognition (might already be stopped):", e.message);
                }
            }
            isRecording = false; 
            if(voiceInputBtn) { 
                voiceInputBtn.classList.remove('recording'); 
                voiceInputBtn.title = "Voice Input"; 
            }
        }

        // --- File & Camera Handling ---
        function handleFileSelect(event){ 
            const file = event.target.files[0];
            if(file && file.type.startsWith('image/')){
                closeCameraModalAndStream(); // Close camera if it was open
                const reader = new FileReader();
                reader.onload = (e) => {
                    if(imagePreview) imagePreview.src = e.target.result;
                    currentBase64Image = e.target.result.split(',')[1]; // Get base64 part
                    currentMimeType = file.type;
                    if(imagePreviewContainer) imagePreviewContainer.classList.remove('hidden');
                };
                reader.readAsDataURL(file);
            } else if (file) {
                showError("Please select a valid image file (e.g., JPG, PNG, GIF).");
                if(fileInput) fileInput.value = null; // Reset file input
            }
        }

        function removeImagePreview(){ 
            if(imagePreview) imagePreview.src = '#'; // Clear preview
            if(imagePreviewContainer) imagePreviewContainer.classList.add('hidden');
            currentBase64Image = null;
            currentMimeType = null;
            if(fileInput) fileInput.value = null; // Reset file input
        }

        async function openCameraModal() { 
            removeImagePreview(); // Clear any existing file preview
            if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) { 
                try { 
                    mediaStream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } }); 
                    if(videoPreviewModal) videoPreviewModal.srcObject = mediaStream; 
                    if(cameraModal) {
                        cameraModal.classList.remove('hidden'); 
                        cameraModal.classList.add('flex'); // Use flex for centering
                    }
                } catch (err) { 
                    showError("Camera access error: " + err.message + ". Please ensure permissions are granted in your browser settings."); 
                    console.error("Camera access error:", err);
                } 
            } else { 
                showError("Camera API is not supported by your browser."); 
            } 
        }

        function closeCameraModalAndStream() { 
            if (mediaStream) { 
                mediaStream.getTracks().forEach(track => track.stop()); 
                mediaStream = null; 
            } 
            if(videoPreviewModal) videoPreviewModal.srcObject = null; 
            if(cameraModal) {
                cameraModal.classList.add('hidden'); 
                cameraModal.classList.remove('flex');
            }
        }

        function captureImageFromModal() { 
            if (!mediaStream || !videoPreviewModal || !videoPreviewModal.videoWidth || videoPreviewModal.videoWidth === 0) { 
                showError("Camera stream is not available or not ready to capture."); 
                return; 
            } 
            const canvas = document.createElement('canvas'); 
            canvas.width = videoPreviewModal.videoWidth; 
            canvas.height = videoPreviewModal.videoHeight; 
            const context = canvas.getContext('2d');
            if (!context) {
                showError("Could not get 2D context from canvas to capture image.");
                return;
            }
            context.drawImage(videoPreviewModal, 0, 0, canvas.width, canvas.height); 
            
            const dataUrl = canvas.toDataURL('image/png'); // Capture as PNG
            if(imagePreview) imagePreview.src = dataUrl; 
            currentBase64Image = dataUrl.split(',')[1]; 
            currentMimeType = 'image/png'; 
            if(imagePreviewContainer) imagePreviewContainer.classList.remove('hidden');
            
            closeCameraModalAndStream(); 
            showError("Image captured! You can now describe it or add text and send your message."); 
        }

        // --- Miscellaneous ---
        function containsVulgar(text){ // Basic placeholder, replace with a robust library or service for production
            if(!text) return false;
            const vulgarWords = ["badword1", "offensiveword2", "exampleprofanity"]; // Add more as needed
            return vulgarWords.some(word => text.toLowerCase().includes(word));
        }
        
        // Adapter for the "Start Voice Chat" button in the non-signed-in view
        function startListeningAdapter() { 
            const mainChatSection = document.getElementById('interactiveChatSection');
            const signInButton = document.getElementById('googleSignInBtnHeader');
            
            if (currentUserId && mainChatSection) { // User is signed in
                mainChatSection.scrollIntoView({ behavior: 'smooth', block: 'start' }); 
                setTimeout(() => { 
                    if (userInput) userInput.focus({preventScroll:true}); // Focus input without scrolling page
                    toggleVoiceInput(); // Start voice input
                }, 300); // Delay to allow scroll to finish
            } else if (signInButton && signInButton.style.display !== 'none') { // User not signed in, prompt to sign in
                signInButton.click(); 
            } else { 
                showError("Please sign in with Google first to use the voice chat feature."); 
            }
        }
        // Make startListeningAdapter globally accessible for the inline HTML onclick attribute
        window.startListeningAdapter = startListeningAdapter; 

    </script>
</body>
</html>
